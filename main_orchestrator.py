"""Main ETL orchestrator for Excel-to-PostgreSQL sync."""

import logging
import os
from datetime import datetime
import pandas as pd
from dotenv import load_dotenv

# Cargar variables de entorno desde .env
load_dotenv()

# Modulos propios
from utils.send_email import send_email_report
from utils.xlsx_extractor import xlsx_to_df
from utils.table_state import get_last_transfer_id
from db.insertion_upsert import insert_new_modified_records


def setup_logging(log_dir="logs", log_file="etl.log"):
    """Configura el sistema de logging para archivos y consola.

    Crea el directorio de logs si no existe y establece un formato est√°ndar
    para todos los mensajes de log. Los logs se escriben tanto a archivo
    como a consola para facilitar el monitoreo.

    Consumers:
        - __main__ (script principal)

    Dependencies:
        - logging (configuraci√≥n b√°sica, handlers, formatters)
        - os.makedirs
        - os.path.join

    Args:
        log_dir (str): Directorio donde se crear√° el archivo de log.
            Default: "logs"
        log_file (str): Nombre del archivo de log.
            Default: "etl.log"

    Returns:
        None: Configura el logging globalmente, no retorna valor.

    Side Effects:
        - Crea directorio log_dir si no existe
        - Configura logging a nivel INFO
        - Establece formato de mensaje con timestamp y nivel
        - A√±ade handlers para archivo y consola
    """
    import sys

    os.makedirs(log_dir, exist_ok=True)
    log_path = os.path.join(log_dir, log_file)

    # Limpiar handlers existentes para evitar duplicaci√≥n
    root_logger = logging.getLogger()
    for handler in root_logger.handlers[:]:
        root_logger.removeHandler(handler)

    # Configurar formato
    formatter = logging.Formatter("%(asctime)s | %(levelname)s | %(message)s")

    # Handler para archivo
    file_handler = logging.FileHandler(log_path, encoding="utf-8")
    file_handler.setFormatter(formatter)

    # Handler para consola (terminal)
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)

    # Configurar logger root
    root_logger.setLevel(logging.INFO)
    root_logger.addHandler(file_handler)
    root_logger.addHandler(console_handler)

    # Mensaje de confirmaci√≥n que deber√≠a aparecer en terminal
    print(f"üîß Sistema de logging configurado - Archivo: {log_path}")
    logging.info(f"Log file: {log_path}")
    logging.info("Sistema de logging iniciado correctamente")


def validate_and_clean_data(df, sheet_name):
    """Valida y limpia datos problem√°ticos (NaN, null, strings vac√≠os).

    Identifica registros con valores problem√°ticos y los separa del conjunto
    de datos a insertar. Retorna el DataFrame limpio y una lista de registros
    problem√°ticos para reporte.

    Args:
        df (pandas.DataFrame): DataFrame a validar y limpiar
        sheet_name (str): Nombre de la hoja para contexto en el reporte

    Returns:
        tuple: (df_clean, problematic_records)
            - df_clean: DataFrame sin registros problem√°ticos
            - problematic_records: Lista de diccionarios con registros problem√°ticos
    """
    import numpy as np

    problematic_records = []
    valid_indices = []

    logging.info(f"Iniciando validaci√≥n de datos para hoja '{sheet_name}'...")

    for index, row in df.iterrows():
        row_issues = []

        # Verificar cada columna del registro
        for col_name, value in row.items():
            # Detectar valores problem√°ticos
            if pd.isna(value) or value is None:
                row_issues.append(f"{col_name}: NaN/None")
            elif isinstance(value, str) and value.strip() == "":
                row_issues.append(f"{col_name}: string vac√≠o")
            elif isinstance(value, (int, float)) and np.isnan(float(value)):
                row_issues.append(f"{col_name}: NaN num√©rico")

        if row_issues:
            # Registro problem√°tico - agregar a lista de problemas
            problematic_record = {
                "index": index,
                "no_transferencia": row.get("no de transferencia", "N/A"),
                "issues": row_issues,
                "sheet": sheet_name,
            }
            problematic_records.append(problematic_record)
            logging.warning(
                f"Registro problem√°tico encontrado - √çndice: {index}, Problemas: {', '.join(row_issues)}"
            )
        else:
            # Registro v√°lido - mantener √≠ndice
            valid_indices.append(index)

    # Crear DataFrame limpio solo con registros v√°lidos
    df_clean = df.loc[valid_indices].copy()

    logging.info(
        f"Validaci√≥n completada - Registros v√°lidos: {len(df_clean)}, Problem√°ticos: {len(problematic_records)}"
    )

    return df_clean, problematic_records


def export_excel_to_postgres(
    sheet_name,
    excel_path,
):
    """Exporta datos desde una hoja de Excel espec√≠fica hacia PostgreSQL.

    Proceso ETL completo que lee datos de Excel, identifica registros nuevos
    bas√°ndose en el √∫ltimo 'no de transferencia' existente en BD, y ejecuta
    inserci√≥n de datos nuevos solamente. El tracking de cambios y updates
    est√°n deshabilitados por dise√±o.

    El proceso incluye:
    - Mapeo autom√°tico de hoja a tabla destino
    - Validaci√≥n de existencia de columna ID
    - Filtrado de registros nuevos vs existentes
    - Confirmaci√≥n interactiva del usuario
    - Inserci√≥n controlada con manejo de errores
    - Env√≠o autom√°tico de reporte por correo

    Consumers:
        - __main__ (loop principal del script)

    Dependencies:
        - utils.xlsx_extractor.xlsx_to_df
        - utils.table_state.get_last_transfer_id
        - db.insertion_upsert.insert_new_modified_records
        - utils.send_email.send_email_report
        - pandas para manipulaci√≥n de datos
        - logging para trazabilidad
        - datetime para medici√≥n de duraci√≥n
        - os.getenv para configuraci√≥n

    Args:
        sheet_name (str): Nombre de la hoja de Excel a procesar.
            Valores soportados: "COMISIONES", "COBRANZA"
        excel_path (str): Ruta completa del archivo Excel a leer.

    Returns:
        None: Ejecuta el proceso ETL completo pero no retorna valores.
            Los resultados se comunican v√≠a logs y email.

    Side Effects:
        - Inserta registros nuevos en PostgreSQL
        - Genera logs detallados del proceso
        - Env√≠a reporte de resultado por correo electr√≥nico
        - Solicita confirmaci√≥n interactiva al usuario

    Environment Variables Required:
        - SCHEMA_TABLE_COMISIONES: Tabla destino para hoja COMISIONES
        - SCHEMA_TABLE_COBRANZA: Tabla destino para hoja COBRANZA
        - RECIPIENT_EMAIL: Destinatario del reporte por correo

    Raises:
        ValueError: Si la hoja no es reconocida o datos son inv√°lidos
        Exception: Errores de BD, lectura de archivo, o configuraci√≥n
    """
    ejecucion_exitosa = False
    error_message = None
    rows_inserted = 0
    status_message = None
    start_time = datetime.now()
    logging.info(f"Inicio proceso hoja: {sheet_name} | {start_time}")

    try:
        # Construir nombres de tablas con esquema entre comillas
        table_name_comisiones = (
            f'"{os.getenv("schema_tables")}".{os.getenv("table_comisiones")}'
        )
        table_name_cobranza = (
            f'"{os.getenv("schema_tables")}".{os.getenv("table_cobranza")}'
        )

        # Log de debug para verificar construcci√≥n de nombres
        logging.info(
            f"Tabla cobranza: {table_name_cobranza}, Tabla comisiones: {table_name_comisiones}"
        )

        # Asignar tabla seg√∫n la hoja
        if sheet_name == "COMISIONES":
            table_name = table_name_comisiones
            logging.info(f'Excel hoja: "{sheet_name.lower()}" | table db: {table_name}')
        elif sheet_name == "COBRANZA":
            table_name = table_name_cobranza
            logging.info(f'Excel hoja: "{sheet_name.lower()}" | table db: {table_name}')
        else:
            error_message = (
                f"Hoja '{sheet_name}' no reconocida. No se realizar√° ninguna operaci√≥n."
            )
            logging.error(error_message)
            return

        id_column = "no de transferencia"
        id_column_db = "no de transferencia"  # Nombre en la BD (con espacios)

        logging.info(f"Procesando hoja '{sheet_name}' para la tabla '{table_name}'.")

        # 1. Obtener el √∫ltimo no de transferencia de la BD
        last_transfer_id, db_status = get_last_transfer_id(table_name, id_column_db)

        # Validar estado de la consulta a DB
        if db_status == "error":
            raise ValueError(
                f"Error de conexi√≥n a la base de datos. No se puede continuar."
            )
        elif db_status == "not_found":
            raise ValueError(
                f"La tabla '{table_name}' no existe en la base de datos. Crear la tabla primero."
            )

        logging.info(
            f"√öltimo no de transferencia en BD: {last_transfer_id} (estado: {db_status})"
        )

        # 2. Lectura del archivo Excel local
        df_excel = xlsx_to_df(excel_path, sheet_name)
        if df_excel is None or df_excel.empty:
            logging.warning("El DataFrame le√≠do del Excel est√° vac√≠o o es None.")
            raise ValueError("El DataFrame le√≠do del Excel est√° vac√≠o o es None.")

        # 3. Validar que el id_column existe en el Excel
        if id_column not in df_excel.columns:
            raise ValueError(f"La columna '{id_column}' no existe en el Excel.")

        # Convertir la columna a num√©rico para comparaciones
        df_excel[id_column] = pd.to_numeric(df_excel[id_column], errors="coerce")

        # 4. Filtrar registros nuevos bas√°ndose en la posici√≥n del √∫ltimo ID de BD en Excel
        # 4. Filtrar registros nuevos bas√°ndose en la posici√≥n del √∫ltimo ID de BD en Excel
        if last_transfer_id is not None and db_status == "ok":
            # Convertir la columna a num√©rico para asegurar coincidencia de tipos
            df_excel[id_column] = pd.to_numeric(df_excel[id_column], errors="coerce")

            # Resetear √≠ndice para asegurar orden secuencial 0..N
            # IMPORTANTE: Trabajamos sobre el df_excel reseteado
            df_reset = df_excel.reset_index(drop=True)

            # Buscar √≠ndices donde coincide el √∫ltimo ID de la BD
            matching_indices = df_reset.index[
                df_reset[id_column] == last_transfer_id
            ].tolist()

            if not matching_indices:
                # El √∫ltimo ID de la BD no est√° en el Excel
                error_msg = (
                    f"El √∫ltimo 'no de transferencia' en BD ({last_transfer_id}) "
                    f"NO se encontr√≥ en el archivo Excel. No es posible determinar el l√≠mite para nuevos registros."
                )
                logging.error(error_msg)
                raise ValueError(error_msg)

            # Si hay duplicados del mismo ID, tomamos el √∫ltimo
            last_match_index = matching_indices[-1]

            logging.info(
                f"Punto de sincronizaci√≥n encontrado: ID {last_transfer_id} en fila {last_match_index} del Excel."
            )

            # Seleccionar todo lo que est√° POR DEBAJO de ese √≠ndice (+1 hasta el final)
            # Aseguramos que seleccionamos todas las filas restantes
            df_new_records = df_reset.iloc[last_match_index + 1 :].copy()

            logging.info(
                f"Registros en Excel: {len(df_excel)} | "
                f"Corte en fila (0-based): {last_match_index} | "
                f"Total filas disponibles: {len(df_reset)} | "
                f"Registros nuevos identificados: {len(df_new_records)}"
            )

            # Debug adicional si parece que no hay nuevos registros pero deber√≠a haberlos
            if df_new_records.empty and last_match_index < len(df_reset) - 1:
                logging.warning(
                    f"¬°Extra√±o! El corte fue en {last_match_index} y el total es {len(df_reset)}, "
                    f"deber√≠a haber {len(df_reset) - 1 - last_match_index} registros, pero df_new_records est√° vac√≠o."
                )

            if not df_new_records.empty:
                ids_preview = df_new_records[id_column].head(10).tolist()
                logging.info(f"Primeros IDs nuevos a insertar: {ids_preview}")

        elif db_status == "empty":
            # Si la tabla est√° vac√≠a, insertar todos los registros
            df_new_records = df_excel
            logging.info(
                f"Tabla vac√≠a. Se insertar√°n todos los registros: {len(df_new_records)}"
            )
        else:
            # Estado inesperado
            raise ValueError(f"Estado inesperado de la base de datos: {db_status}")

        # 5. Verificar si hay datos para insertar
        if df_new_records.empty:
            logging.info(
                "No hay inserciones. No existen registros nuevos posteriores al √∫ltimo ID en BD."
            )
            ejecucion_exitosa = True
            status_message = f"No hay datos nuevos para insertar. √öltimo ID en BD: {last_transfer_id}"
            return

        # 6. Validar y limpiar datos problem√°ticos
        df_clean_records, problematic_records = validate_and_clean_data(
            df_new_records, sheet_name
        )

        # Verificar si quedan registros v√°lidos despu√©s de la limpieza
        if df_clean_records.empty:
            logging.warning(
                "No hay registros v√°lidos para insertar despu√©s de la limpieza de datos."
            )
            ejecucion_exitosa = True
            status_message = f"Todos los registros nuevos tienen datos problem√°ticos. Se encontraron {len(problematic_records)} registros con errores."
            # Almacenar registros problem√°ticos para el email
            globals()["problematic_records_global"] = problematic_records
            return

        # usado para verificar que se est√°n filtrando correctamente los registros nuevos
        confirmation_message = f"Se encontraron {len(df_new_records)} registros nuevos."
        if problematic_records:
            confirmation_message += (
                f"\n- Registros v√°lidos a insertar: {len(df_clean_records)}"
            )
            confirmation_message += f"\n- Registros con problemas (se excluir√°n): {len(problematic_records)}"
        else:
            confirmation_message += f" Todos son v√°lidos para insertar."

        confirmation_message += "\n¬øDesea continuar? (s/n): "

        response_user = input(confirmation_message)
        if response_user.lower() != "s":
            logging.info("Proceso cancelado por el usuario.")
            return

        # Almacenar registros problem√°ticos para el email (variable global temporal)
        globals()["problematic_records_global"] = problematic_records

        # 7. Ejecutar inserci√≥n (sin modificaciones, solo nuevos y v√°lidos)
        df_empty = df_excel.iloc[0:0]  # DataFrame vac√≠o para modificados
        insert_new_modified_records(df_clean_records, df_empty, table_name, id_column)

        logging.info(f"Inserciones completadas. Filas nuevas: {len(df_clean_records)}")
        rows_inserted = len(df_clean_records)
        status_message = f"Inserciones completadas. √öltimo ID insertado: {df_clean_records[id_column].max()}"
        if problematic_records:
            status_message += (
                f" | {len(problematic_records)} registros con problemas excluidos"
            )
        ejecucion_exitosa = True

    except Exception as e:
        logging.exception(f"Error en el proceso ETL: {e}")
        error_message = str(e)

    finally:
        end_time = datetime.now()
        duration = end_time - start_time
        logging.info(
            "Fin proceso hoja: %s | %s | duracion: %s",
            sheet_name,
            end_time,
            duration,
        )

        # Enviar correo de reporte (SIEMPRE SE EJECUTA)
        # Obtener registros problem√°ticos de variable global temporal
        problematic_records_email = globals().get("problematic_records_global", [])

        if ejecucion_exitosa:
            subject = "‚úÖ ETL-Excel a PostgreSQL - √âXITO"
            body = (
                f"proceso ETL para la hoja '{sheet_name}' se complet√≥ exitosamente.\n"
                f"Duraci√≥n: {duration},\nFilas nuevas insertadas: {rows_inserted}\n"
                f"Estado: {status_message or 'OK'}"
            )

            # A√±adir informaci√≥n sobre registros problem√°ticos si los hay
            if problematic_records_email:
                body += "\n\n‚ö†Ô∏è REGISTROS CON DATOS PROBLEM√ÅTICOS EXCLUIDOS:\n"
                body += f"Total de registros problem√°ticos: {len(problematic_records_email)}\n\n"
                for i, record in enumerate(
                    problematic_records_email[:10], 1
                ):  # Mostrar m√°ximo 10
                    body += f"{i}. No. Transferencia: {record['no_transferencia']} | Problemas: {', '.join(record['issues'])}\n"

                if len(problematic_records_email) > 10:
                    body += f"... y {len(problematic_records_email) - 10} registros m√°s con problemas.\n"

                body += "\nEstos registros NO fueron insertados en la base de datos y requieren correcci√≥n manual en el archivo Excel."
        else:
            subject = "‚ùå ETL-Excel a PostgreSQL - FALL√ì"
            # Aqu√≠ vendr√° el mensaje de 'API Key inv√°lida'
            body = (
                "Error:\n"
                f"{error_message or 'Fallo no especificado.'}\n\n"
                "Revisar el log adjunto para m√°s detalles."
            )

            # A√±adir informaci√≥n sobre registros problem√°ticos incluso en caso de error
            if problematic_records_email:
                body += "\n\n‚ö†Ô∏è REGISTROS CON DATOS PROBLEM√ÅTICOS ENCONTRADOS (antes del error):\n"
                body += f"Total: {len(problematic_records_email)}\n"
                for i, record in enumerate(
                    problematic_records_email[:5], 1
                ):  # Menos registros en caso de error
                    body += f"{i}. No. Transferencia: {record['no_transferencia']} | Problemas: {', '.join(record['issues'])}\n"

        log_path = log_file
        if log_file and not os.path.isabs(log_file):
            log_path = os.path.join("logs", log_file)

        # Obtener emails de destinatarios (principal + adicional)
        primary_email = os.getenv("RECIPIENT_EMAIL")
        if not primary_email:
            logging.error("Variable de entorno RECIPIENT_EMAIL no est√° configurada")
            primary_email = "becario.bi@lazarza.com.mx"  # Email de respaldo en caso de falta de configuraci√≥n

        secondary_email = "esp.bi02@lazarza.com.mx"

        # Combinar destinatarios
        recipients = f"{primary_email},{secondary_email}"

        send_email_report(
            subject=subject,
            body=body,
            recipient=recipients,
            attachment_path=log_path,
        )


# RUTA DEL ARCHIVO EXCEL LOCAL (configurable v√≠a variable de entorno)
EXCEL_PATH = os.getenv("EXCEL_FILE_PATH")
logging.info(f"Ruta del archivo Excel configurada: {EXCEL_PATH}")
# # TABLE_NAME = "DataMart.presupuestos_planeacion" - teoricamente esto ya se maneja dentro de la funcion
# TABLE_NAME = "excel_etl_testing.test_data_insertions_cobranza"  # pruebas en local
sheets_name = ["COBRANZA", "COMISIONES"]
if __name__ == "__main__":
    log_file = f"etl.{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    setup_logging(log_file=log_file)
    process_start = datetime.now()
    logging.info(f"Inicio proceso ETL: {process_start}")

    for sheet in sheets_name:
        if sheet:  # Solo procesar si el nombre de la hoja no est√° vac√≠o
            logging.info(f"Procesando hoja: {sheet}")
            export_excel_to_postgres(sheet, EXCEL_PATH)

    process_end = datetime.now()
    logging.info(f"Fin proceso ETL: {process_end}")
    logging.info(f"Duracion total ETL: {process_end - process_start}")
